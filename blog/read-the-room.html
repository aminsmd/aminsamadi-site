<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Read the Room or Lead the Room - Amin Samadi</title>
    <link rel="stylesheet" href="../css/style.css">
</head>
<body>
    <nav>
        <div class="container">
            <a href="../index.html" class="logo">Amin Samadi</a>
            <div class="nav-links">
                <a href="../about.html">About</a>
                <a href="index.html" class="active">Research</a>
                <a href="../photography.html">Photography</a>
            </div>
        </div>
    </nav>

    <main>
        <div class="container">
            <article>
                <div class="post-header">
                    <h1>Read the Room or Lead the Room</h1>
                    <p class="subtitle">What Happens When Your Teammate Is an AI?</p>
                    <p class="meta">February 26, 2026</p>
                </div>

                <div class="post-content">
                    <p>Picture this: your team is working through a tough problem. Someone cracks a joke to ease the tension. Another teammate picks up on the frustration in the room and suggests a quick break. These micro-moments of social awareness are the invisible glue of collaboration.</p>

                    <p>Now imagine one of your teammates is an AI. What happens to that glue?</p>

                    <p>We ran an experiment with 179 students across 74 teams, comparing groups of three humans against groups of two humans plus one AI teammate. The AI wasn't a simple chatbot—it was a fully autonomous GPT-4 agent with memory, designed to collaborate, co-construct knowledge, and adapt to its teammates.</p>

                    <p>What we found reveals a fundamental tension in human-AI collaboration.</p>

                    <h2>The AI That Couldn't Read the Room</h2>

                    <p>Our AI teammate excelled at cognitive tasks. It used leadership language, analytical reasoning, and future-focused planning. It drove decisions forward and kept the group organized.</p>

                    <div class="finding">
                        <p><strong>But it missed the social cues entirely.</strong> When a human teammate said "fire" (slang for "that's excellent"), the AI responded literally—explaining how fire cannot burn on the moon due to lack of oxygen.</p>
                    </div>

                    <p>Despite being prompted to mirror teammates' tone and remain empathetic, the AI showed limited ability to recognize informal or affective signals. Its contributions were verbose and repetitive—about three times longer than human messages—with low novelty and communication density.</p>

                    <img src="../images/read-the-room/fig-000.png" alt="LIWC comparison of AI vs Treatment Humans">
                    <p class="caption">AI teammates dominated on word count, leadership language (clout), analytical reasoning, and collective pronouns ("we"), while humans used more first-person singular ("I").</p>

                    <img src="../images/read-the-room/fig-002.png" alt="Group Communication Analysis comparison">
                    <p class="caption">AI showed high internal cohesion but very low newness and communication density—verbose but repetitive.</p>

                    <h2>How Humans Adapted</h2>

                    <p>The most striking finding wasn't about the AI. It was about the humans.</p>

                    <div class="callout">
                        <h4>Role Redistribution</h4>
                        <p>When collaborating with AI, humans shifted toward more social roles—using significantly more polite, socially-oriented language to compensate for the AI's deficits.</p>
                    </div>

                    <div class="callout">
                        <h4>The Secretary Effect</h4>
                        <p>Once humans identified the AI (recognizable by its flat tone and lengthy messages), they started treating it as a secretary—offloading organizational tasks, asking for summaries, and deferring on decisions.</p>
                    </div>

                    <div class="callout">
                        <h4>Cognitive Offloading</h4>
                        <p>With the AI handling reasoning and planning, humans provided shorter, often passive, affirming responses. Their deeper cognitive engagement declined.</p>
                    </div>

                    <img src="../images/read-the-room/fig-004.png" alt="LIWC comparison of Treatment vs Control Humans">
                    <p class="caption">Humans working with AI (orange) used more social, communicative, and polite language compared to human-only teams (blue).</p>

                    <h2>Lead vs. Read</h2>

                    <p>The title captures the core tension: AI teammates tend to <em>lead</em> the room cognitively but fail to <em>read</em> the room socially.</p>

                    <blockquote>
                        "The AI dominated decision-making while humans retreated into social support roles—fundamentally reshaping the collaborative dynamic."
                    </blockquote>

                    <p>This isn't necessarily bad. But it's different. And if we're not intentional about it, we risk designing AI teammates that undermine the very engagement they're meant to support.</p>

                    <h2>What This Means for Design</h2>

                    <div class="takeaways">
                        <h4>Implications</h4>
                        <ul>
                            <li><strong>Simply adding AI isn't enough.</strong> Intentional design is needed to support—rather than dominate—group dynamics.</li>
                            <li><strong>Social awareness matters.</strong> AI teammates that miss affective cues risk reducing human engagement and sense of belonging.</li>
                            <li><strong>Watch for cognitive offloading.</strong> When AI handles all the reasoning, humans may disengage from deeper thinking.</li>
                            <li><strong>Consider AI personas.</strong> A less agreeable, more questioning AI might foster different—possibly healthier—collaboration patterns.</li>
                        </ul>
                    </div>

                    <h2>The Bottom Line</h2>

                    <p>AI teammates are powerful cognitive collaborators. But collaboration isn't just cognition. It's reading frustration in a teammate's message. It's knowing when to push forward and when to pause. It's understanding that "fire" sometimes means enthusiasm, not combustion.</p>

                    <p>Until AI can read the room as well as it leads it, human teammates will keep filling the gap—for better or worse.</p>

                    <p style="margin-top: 40px;"><strong>Read the paper:</strong> <a href="https://arxiv.org/abs/2510.09944" target="_blank">Read the Room or Lead the Room: Understanding Socio-Cognitive Dynamics in Human-AI Teaming</a></p>

                    <p style="text-align: center; margin-top: 40px; color: var(--text-muted);">Thanks for reading!</p>
                </div>
            </article>
        </div>
    </main>

    <footer>
        <div class="container">
            <span>Amin Samadi</span>
            <div class="social-links">
                <a href="mailto:masamadi@uci.edu">Email</a>
                <a href="https://github.com/aminsmd" target="_blank">GitHub</a>
                <a href="https://scholar.google.com/citations?user=fp1tVhIAAAAJ" target="_blank">Scholar</a>
                <a href="https://twitter.com/aminsamadi_" target="_blank">Twitter</a>
                <a href="https://www.linkedin.com/in/aminsamadi/" target="_blank">LinkedIn</a>
            </div>
        </div>
    </footer>
    <script src="../js/main.js"></script>
</body>
</html>
